{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the TTGammaProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will copy the test files from their location on eos to your local area. This only needs to be done once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #If you have not already done so, you can copy the files to test the code on from here\n",
    "# # ONLY NEEDS TO BE DONE ONCE, CAN BE COMMENTED OUT WHEN YOU \n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTGamma_1l.root .\n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/TTbar_1l.root .\n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/WGamma.root .\n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/ZGamma.root .\n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/W4Jets.root .\n",
    "# !xrdcp root://cmseos.fnal.gov//store/user/cmsdas/2021/long_exercises/TTGamma/TestFiles/ZJets.root ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from coffea import util, processor\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea import hist\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of samples to be run on (fileset variable) and a dictionary containing the number of events processed for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {'TTGamma_SingleLept':['TTGamma_1l.root'],\n",
    "           'TTbarPowheg_Semilept':['TTbar_1l.root'],\n",
    "           'W4jets':['W4Jets.root'],\n",
    "           'WGamma_01J_5f':['WGamma.root'],\n",
    "           'ZGamma_01J_5f_lowMass':['ZGamma.root'],\n",
    "           'DYjetsM50':['ZJets.root'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the TTGammaProcessor on the list of files included in fileset.\n",
    "\n",
    "You can specify the chunksize and maximum number of chunks to process from each sample (selecting a small number of events and one chunk will force coffea to process only a subset of the events for quicker debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoreload forces the kernel to reload the processor to include any new changes\n",
    "%autoreload 2\n",
    "from ttgamma import TTGammaProcessor\n",
    "import awkward as ak\n",
    "\n",
    "import time\n",
    "tstart = time.time()\n",
    "\n",
    "#Run Coffea code using uproot\n",
    "output2 = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    \"Events\",\n",
    "    TTGammaProcessor(isMC=True),\n",
    "    processor.iterative_executor,\n",
    "    executor_args={'schema': NanoAODSchema,'workers': 4},\n",
    "    chunksize=50000,\n",
    "#     maxchunks=-1,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(\"Total time: %.1f seconds\"%elapsed)\n",
    "print(\"Total rate: %.1f events / second\"%(output['EventCount'].value/elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "hist.plot1d(output['photon_chIso'].sum('category').sum('lepFlavor').integrate('dataset','TTGamma_SingleLept'), overlay='systematic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['M3'].sum('category').sum('lepFlavor').integrate('dataset','TTGamma_SingleLept'), overlay='systematic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['photon_eta'].sum('category').sum('lepFlavor').integrate('dataset','TTGamma_SingleLept'), overlay='systematic') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['photon_lepton_mass_3j0t'].sum('category').sum('lepFlavor').integrate('systematic','nominal'), overlay='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(output['M3'].sum('category').sum('lepFlavor').integrate('systematic','nominal'), overlay='dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "from coffea import hist, util\n",
    "\n",
    "from ttgamma.utils.plotting import plotWithRatio, RebinHist, SetRangeHist\n",
    "\n",
    "grouping= {'$t\\overline{t}+\\gamma$': ['TTGamma_Dilepton','TTGamma_SingleLept','TTGamma_Hadronic'],\n",
    "            '$t\\overline{t}$'  : ['TTbarPowheg_Dilepton', 'TTbarPowheg_Semilept', 'TTbarPowheg_Hadronic'],\n",
    "            'Single top':['ST_s_channel', 'ST_tW_channel', 'ST_tbarW_channel', 'ST_tbar_channel', 'ST_t_channel'],\n",
    "            'W+jets':['W1jets', 'W2jets', 'W3jets', 'W4jets'],\n",
    "            'Z+jets'  : ['DYjetsM10to50', 'DYjetsM50'],\n",
    "            'W+$\\gamma$' : ['WGamma_01J_5f'],\n",
    "            'Z+$\\gamma$' : ['ZGamma_01J_5f_lowMass'],\n",
    "            'TTV'    : ['TTWtoLNu','TTWtoQQ','TTZtoLL'],\n",
    "            'GJets'  : [ 'GJets_HT40To100', 'GJets_HT100To200', 'GJets_HT200To400', 'GJets_HT400To600', 'GJets_HT600ToInf'],\n",
    "            'QCD'    :['QCD_Pt20to30_Ele', 'QCD_Pt30to50_Ele', 'QCD_Pt50to80_Ele', 'QCD_Pt80to120_Ele', 'QCD_Pt120to170_Ele', 'QCD_Pt170to300_Ele', 'QCD_Pt300toInf_Ele', 'QCD_Pt20to30_Mu', 'QCD_Pt30to50_Mu', 'QCD_Pt50to80_Mu', 'QCD_Pt80to120_Mu', 'QCD_Pt120to170_Mu', 'QCD_Pt170to300_Mu', 'QCD_Pt300to470_Mu', 'QCD_Pt470to600_Mu', 'QCD_Pt600to800_Mu', 'QCD_Pt800to1000_Mu', 'QCD_Pt1000toInf_Mu'],\n",
    "  }\n",
    "\n",
    "groupCategory= {\"Genuine $\\gamma$\": slice(1,2),\n",
    "                \"MisID e\":slice(2,3),\n",
    "                \"NonPrompt\":slice(3,5),\n",
    "               }\n",
    "\n",
    "\n",
    "#Get photon pt distribution from coffea output\n",
    "h = output['photon_pt']\n",
    "\n",
    "#sum over lepton flavors (get both electron and muon)\n",
    "h = h.sum('lepFlavor')\n",
    "\n",
    "#integrate over systematics, selecting only \"nominal\"\n",
    "h = h.integrate('systematic','nominal')\n",
    "\n",
    "#group the datasets into the sample types\n",
    "h = h.group('dataset',hist.Cat(r'dataset',r'Samples',sorting='placement'),grouping)\n",
    "\n",
    "#group the photon category axis into the category types listed above\n",
    "h = h.group('category',hist.Cat(r'category',r'Category',sorting='placement'),groupCategory)\n",
    "\n",
    "#rebin the pt axis\n",
    "h = h.rebin(\"pt\",hist.Bin(\"pt\",h.axis(\"pt\").label,np.array([20,25,30,35,40,45,50,60,70,80,90,100,120,140,160,180,200,250,300,400,500])))\n",
    "\n",
    "hData = output['photon_pt'].sum('lepFlavor').sum('systematic').sum('dataset').sum('category')\n",
    "hData = hData.rebin(\"pt\",hist.Bin(\"pt\",h.axis(\"pt\").label,np.array([20,25,30,35,40,45,50,60,70,80,90,100,120,140,160,180,200,250,300,400,500])))\n",
    "\n",
    "plotWithRatio(h.sum('category'), hData, overlay='dataset', invertStack=True, binwnorm=1., xRange=[20,500], yRange=[5e-2,None], logY=True,leg='right')\n",
    "plotWithRatio(h.sum('dataset'), hData, overlay='category', invertStack=True, binwnorm=1., xRange=[20,500], yRange=[5e-2,None], logY=True,leg='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Arrays Interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of loading a NanoAOD file interactively. This can be very useful for developing the code, and debugging any issues. Use this area to build your intuition for working with Coffea and awkward arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "\n",
    "fname = \"./TTGamma_1l.root\"\n",
    "events = NanoEventsFactory.from_root(fname, schemaclass=NanoAODSchema).events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have opened the file, you can explore its contents using the 'fields' syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.GenPart.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a docstring for each of these variables in NanoAOD, which you can access using '?':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Jet.rawFactor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import hist, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puLookup = util.load('/ScaleFactors/puLookup.coffea')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttgenv",
   "language": "python",
   "name": "ttgenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
